{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c91ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(4, input_shape=(1,), activation='relu', use_bias=True, bias_initializer='zeros'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4abeaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.23354697,  0.8906412 , -0.554768  , -1.0749171 ]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.9972789 , -0.00777841],\n",
       "        [-0.7555084 ,  0.6331384 ],\n",
       "        [-0.40341663, -0.93983436],\n",
       "        [ 0.23229241, -0.24736404]], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() #here zeros are b values and 1st array are weights 2nd array are bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6358b",
   "metadata": {},
   "source": [
    "This gives us all the weights and all the biases for each layer in the model. We can see that we have these randomly initialized weights in the weight matrix for the first hidden layer, and we also have the bias vector containing 4 zeros corresponding to the bias term for each node in the layer for which we specified 'zeros' as the bias_initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2628c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential([\n",
    "        Dense(3, input_shape=(2,), activation='relu'),\n",
    "        Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd74883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 17\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc28198",
   "metadata": {},
   "source": [
    "During the training process, we've discussed how stochastic gradient descent, or SGD, works to learn and optimize the weights and biases in a neural network. These weights and biases are indeed learnable parameters.\n",
    "here dense_2= weight(2x3) +bias(3) =9\n",
    "dense_3 =weight(3x2)+bias(2) =8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6a5c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.8724664 , -0.67773575,  0.93182826],\n",
       "        [-0.7709249 , -0.1191901 , -0.48561996]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 1.0493152 ,  0.23365188],\n",
       "        [-0.23160928, -0.5445464 ],\n",
       "        [ 0.3501569 , -0.70905817]], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc880d",
   "metadata": {},
   "source": [
    "# Trainable Parameters In A Keras Convolutional Neural Network(Filters in a convolutional neural network learnable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd22416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.pooling import *\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(\n",
    "        2\n",
    "        , kernel_size=(3,3)\n",
    "        , input_shape=(20,20,3)\n",
    "        , activation='relu'\n",
    "        , padding='same'\n",
    "    ),\n",
    "    Conv2D(\n",
    "        3\n",
    "        , kernel_size=(3,3)\n",
    "        , activation='relu'\n",
    "        , padding='same'\n",
    "    ),\n",
    "    Flatten(),\n",
    "    Dense(\n",
    "        2, \n",
    "        activation='softmax'\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127b34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58183e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 2)         56        \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 3)         57        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 2402      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,515\n",
      "Trainable params: 2,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fb44d06",
   "metadata": {},
   "source": [
    "Input Layer\n",
    "Now, the same rule applies here for the input layer that we talked about last time. The input layer has no learnable parameters since it just contains the input data.\n",
    "\n",
    "Conv Layer 1\n",
    "Moving on to the first hidden convolutional layer, how many inputs do we have coming into this layer? We have 3 from our input layer. How many outputs? Well, let's see. Remember, the number of outputs is the number of filters times the filter size. So we have two filters, each of size 3x3. So 2*3*3 = 18. Multiplying our three inputs by our 18 outputs, we have 54 weights. Now how many biases? Just two, since the number of biases is equal to the number of filters. So that gives us 56 total learnable parameters in this layer.\n",
    "\n",
    "Conv Layer 2\n",
    "Now let's move to our next convolutional layer. How many inputs are coming in to this layer? We have two from the number of filters in the previous layer. How many outputs? Well, we have three filters, again of size 3x3. So that's 3*3*3 = 27 outputs. Multiplying our two inputs by the 27 outputs, we have 54 weights in this layer. Adding three bias terms from the three filters, we have 57 learnable parameters in this layer .\n",
    "\n",
    "Output Layer\n",
    "Since we're assuming that this network uses zero padding, the dimensions of our images of size 20x20 haven't changed by the time we get to this layer. So multiplying 20x20 by the three filters gives us a total of 1200 inputs coming in to our output layer.\n",
    "Now, since this output layer is a dense\n",
    "layer, the number of outputs is just equal to the number of nodes in this layer, so we have two outputs. Multiplying 1200*2 gives us 2400 weights. Adding in our two biases from this layer, we have 2402 learnable parameters in this layer.\n",
    "\n",
    "2402+57+56 = 2515"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a213f81a",
   "metadata": {},
   "source": [
    "# Keras Model With Zero-Padding And Max-Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797d0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(2, kernel_size=(3,3), input_shape=(20,20,3), activation='relu', padding='same'),\n",
    "    Conv2D(3, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48cc85a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 20, 20, 2)         56        \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 20, 20, 3)         57        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 10, 10, 3)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 602       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 715\n",
      "Trainable params: 715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "What happens to the dimensions of image data when passed to a MaxPooling2D layer with pool_size=(2,2) and stride=2?\n",
    "\n",
    "The image dimensions are decreased by a factor of 2\n",
    "\n",
    "therefore no of learining parameters go down"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
